{
 "cells": [
  {
   "cell_type": "raw",
   "id": "96ac30d6-ed79-4874-883a-5362d4ac9481",
   "metadata": {},
   "source": [
    "Q1- Explain the following with an example\n",
    "\n",
    "1) Artificial Intelligence\n",
    "2) Machine Learning\n",
    "3) Deep Learning\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5c130-fea6-41ae-9ef0-332728111b43",
   "metadata": {},
   "source": [
    "1.Artificial Intelligence (AI):\n",
    "\n",
    "Artificial Intelligence refers to the simulation of human intelligence in machines, allowing them to perform tasks that typically require human intelligence, such as problem-solving, decision-making, speech recognition, and language translation. AI systems are designed to mimic cognitive functions like learning and problem-solving, enabling them to adapt and improve their performance over time.\n",
    "\n",
    "Example: An AI-powered virtual assistant like Siri or Google Assistant can understand natural language, answer questions, set reminders, and perform tasks based on user input. These systems use AI techniques to process language, analyze user intent, and provide appropriate responses.\n",
    "\n",
    "2.Machine Learning (ML):\n",
    "\n",
    "Machine Learning is a subset of AI that involves training a machine to learn from data rather than being explicitly programmed. It focuses on the development of algorithms that allow computers to learn patterns and make predictions or decisions based on input data. ML algorithms improve their performance as they are exposed to more data.\n",
    "\n",
    "Example: Email spam filters are a common application of machine learning. By analyzing a large dataset of emails labeled as \"spam\" or \"not spam,\" a machine learning algorithm can learn to recognize patterns that differentiate between the two categories. As more data is fed into the system, the algorithm's accuracy in classifying new emails as spam or not spam improves.\n",
    "\n",
    "3.Deep Learning:\n",
    "\n",
    "Deep Learning is a subset of machine learning that involves the use of artificial neural networks to model and solve complex problems. These neural networks are inspired by the structure of the human brain and consist of layers of interconnected nodes that process and transform data. Deep Learning has been particularly successful in tasks involving large amounts of unstructured data, such as images, audio, and text.\n",
    "\n",
    "Example: Image recognition is a classic example of deep learning. A deep neural network can be trained to recognize objects within images. For instance, a deep learning model can be trained on a vast dataset of labeled images of cats and dogs. The model's layers learn to identify features like edges, textures, and shapes, eventually enabling it to accurately classify new images as either cats or dogs.\n",
    "\n",
    "Artificial Intelligence is the overarching concept of creating machines that can perform tasks intelligently. Machine Learning is a subset of AI that involves training machines to learn from data. Deep Learning is a subset of machine learning that uses neural networks to handle complex tasks and unstructured data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bf6b49e-3d1b-4a82-86a3-dc0bb2346878",
   "metadata": {},
   "source": [
    "Q2- What is supervised learning?List some example of superviesd learning.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c521b-3e5c-4d0c-8d19-2fa950ad4c4c",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning where a model is trained using labeled data to learn the mapping between input features and corresponding output labels. In other words, the model learns to make predictions or decisions based on the relationship between input-output pairs present in the training data. The term \"supervised\" refers to the fact that the training process involves a \"supervisor\" or \"teacher\" providing the correct answers (labels) for the given inputs, so the model can learn to generalize its predictions to unseen data.\n",
    "\n",
    "In supervised learning, the goal is to create a predictive model that can accurately map new, unseen input data to the correct output labels. This process involves finding patterns, relationships, or features in the training data that can help the model generalize its predictions.\n",
    "\n",
    "Examples of supervised learning tasks include:\n",
    "\n",
    "1.Classification: This involves assigning input data to a predefined class or category. For instance:\n",
    "\n",
    "Email spam detection: Classifying emails as \"spam\" or \"not spam.\"\n",
    "\n",
    "Image classification: Categorizing images into various classes, such as identifying animals, objects, or people in images.\n",
    "\n",
    "Medical diagnosis: Diagnosing diseases based on patient data and medical test results.\n",
    "\n",
    "2.Regression: This involves predicting a continuous numerical value or quantity. For instance:\n",
    "\n",
    "House price prediction: Predicting the selling price of a house based on features like location, size, and amenities.\n",
    "\n",
    "Temperature forecasting: Predicting the temperature for a specific date based on historical weather data.\n",
    "\n",
    "Stock price prediction: Predicting the future value of a stock based on historical market data.\n",
    "\n",
    "3.Semantic Segmentation: This involves assigning a label to each pixel in an image, which is used in tasks like image segmentation or object localization.\n",
    "\n",
    "4.Language Translation: Translating text from one language to another, where the input is a sentence in one language and the output is the same sentence in another language.\n",
    "\n",
    "5.Named Entity Recognition (NER): Identifying entities such as names of people, organizations, locations, etc., in a text.\n",
    "\n",
    "6.Handwriting Recognition: Converting handwritten text or symbols into digital text."
   ]
  },
  {
   "cell_type": "raw",
   "id": "61d18b5b-8e4b-4054-9a65-ebafdeacd139",
   "metadata": {},
   "source": [
    "Q3-What is unsupervised learning?List some example of unsuperviesd learning.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0c0dc-9bb1-43b9-b140-fd70a988e449",
   "metadata": {},
   "source": [
    "Unsupervised learning is a type of machine learning where the model is trained on unlabeled data, meaning that there are no corresponding output labels provided during the training process. Instead, the model's goal is to find inherent patterns, relationships, or structures within the data without any explicit guidance on what the output should be. Unsupervised learning is particularly useful for tasks where you want to explore the data's inherent structure or discover hidden patterns.\n",
    "\n",
    "Here are some examples of unsupervised learning tasks:\n",
    "\n",
    "1.Clustering: Clustering involves grouping similar data points together into clusters based on some similarity metric. It's useful for discovering natural groupings within data.\n",
    "\n",
    "Customer segmentation: Grouping customers based on their purchasing behavior to target specific marketing strategies.\n",
    "\n",
    "Document clustering: Organizing a large collection of documents into topics or themes.\n",
    "\n",
    "2.Dimensionality Reduction: This involves reducing the number of features or dimensions in the data while retaining its important information. It's useful for visualizing and analyzing high-dimensional data.\n",
    "\n",
    "Principal Component Analysis (PCA): Reducing the dimensions of a dataset while preserving as much variance as possible.\n",
    "\n",
    "t-SNE (t-Distributed Stochastic Neighbor Embedding): Visualizing high-dimensional data in a lower-dimensional space while preserving local structure.\n",
    "\n",
    "3.Anomaly Detection: Anomaly detection focuses on identifying data points that are significantly different from the rest of the data. It's useful for detecting outliers or anomalies in datasets.\n",
    "\n",
    "Fraud detection: Identifying unusual transactions in financial data that might indicate fraudulent activities.\n",
    "\n",
    "Equipment failure prediction: Detecting anomalies in sensor data from machinery to predict when a machine might fail.\n",
    "\n",
    "4.Topic Modeling: Topic modeling is the process of uncovering latent topics within a collection of documents.\n",
    "\n",
    "Latent Dirichlet Allocation (LDA): A probabilistic model that identifies topics in a collection of documents and assigns words to those topics.\n",
    "\n",
    "5.Recommendation Systems: These systems suggest items or content to users based on their preferences and behaviors.\n",
    "\n",
    "Collaborative filtering: Recommending products or movies to users based on the preferences of similar users.\n",
    "\n",
    "Content-based filtering: Recommending items to users based on their past interactions with similar items.\n",
    "\n",
    "6.Density Estimation: Estimating the probability density function of the data points. Useful for understanding the distribution of data.\n",
    "\n",
    "Gaussian Mixture Models (GMM): Modeling data as a mixture of several Gaussian distributions.\n",
    "\n",
    "7.Data Preprocessing: Some unsupervised techniques are used as preprocessing steps for supervised learning tasks.\n",
    "\n",
    "Feature scaling: Scaling features to the same range to improve the performance of algorithms like neural networks or support vector machines.\n",
    "\n",
    "Unsupervised learning doesn't have explicit target outputs to guide the learning process, which makes it more challenging and often requires more exploration and interpretation of results compared to supervised learning."
   ]
  },
  {
   "cell_type": "raw",
   "id": "65c687c3-4490-476b-8caf-bd021e2b5b91",
   "metadata": {},
   "source": [
    "Q4- What is the difference between AI, ML, DL, and DS?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63a01f-2395-4d5f-952a-8319848757a2",
   "metadata": {},
   "source": [
    "AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are related but distinct fields within the broader realm of computer science and technology. Here's a breakdown of the differences between these terms:\n",
    "\n",
    "1.AI (Artificial Intelligence):\n",
    "\n",
    "AI refers to the broader concept of machines or computer systems performing tasks that typically require human intelligence. The goal of AI is to create systems that can mimic human cognitive functions, such as reasoning, problem-solving, understanding natural language, and learning from experience.\n",
    "\n",
    "AI encompasses a wide range of techniques, including rule-based systems, expert systems, machine learning, and more recently, deep learning.\n",
    "Example: Developing a system that can play chess at a master level by analyzing board positions and making strategic moves.\n",
    "\n",
    "2.ML (Machine Learning):\n",
    "\n",
    "Machine Learning is a subset of AI that focuses on the development of algorithms that enable computers to learn from and make predictions or decisions based on data.\n",
    "\n",
    "ML algorithms learn patterns and relationships in data to make accurate predictions or decisions without being explicitly programmed.\n",
    "\n",
    "Supervised, unsupervised, and reinforcement learning are common types of ML techniques.\n",
    "\n",
    "Example: Training a model to recognize images of cats and dogs by providing labeled training images.\n",
    "\n",
    "3.DL (Deep Learning):\n",
    "\n",
    "Deep Learning is a subset of machine learning that specifically utilizes neural networks with multiple layers (deep neural networks) to model and solve complex problems.\n",
    "\n",
    "Deep Learning has shown exceptional performance in tasks such as image and speech recognition, natural language processing, and more.\n",
    "\n",
    "Deep Learning algorithms automatically learn features from data, allowing them to handle high-dimensional and unstructured data effectively.\n",
    "\n",
    "Example: Training a deep neural network to classify objects in images using a large dataset.\n",
    "\n",
    "4.DS (Data Science):\n",
    "\n",
    "Data Science is an interdisciplinary field that involves extracting insights and knowledge from data using various techniques, including statistics, machine learning, data visualization, and domain expertise.\n",
    "\n",
    "Data Scientists gather, clean, preprocess, analyze, and interpret data to solve complex problems and make data-driven decisions.\n",
    "\n",
    "Data Science encompasses various stages, including data collection, data cleaning, feature engineering, modeling, and interpretation of results.\n",
    "\n",
    "Example: Analyzing customer data to identify trends and patterns that can inform business strategies.\n",
    "In summary:\n",
    "\n",
    "AI is the broader concept of machines performing tasks that require human intelligence.\n",
    "\n",
    "ML is a subset of AI that involves algorithms learning from data to make predictions or decisions.\n",
    "\n",
    "DL is a subset of ML that uses deep neural networks to handle complex tasks.\n",
    "\n",
    "DS is an interdisciplinary field that focuses on extracting insights from data to solve real-world problems."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8def4e30-6c9d-4ceb-9d5b-6d148e77650e",
   "metadata": {},
   "source": [
    "Q5- What are the main difference between supervised, unsupervised, and semi-supervised learning?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f1327-75ca-4e60-8571-e19b4ff14a85",
   "metadata": {},
   "source": [
    "Supervised, unsupervised, and semi-supervised learning are different approaches within the field of machine learning, each with its own characteristics and use cases. Here are the main differences between these three types of learning:\n",
    "\n",
    "1.Supervised Learning:\n",
    "\n",
    "Definition: In supervised learning, the model is trained on a labeled dataset, where each input example is paired with its corresponding output label.\n",
    "\n",
    "Objective: The goal is to learn a mapping from input features to output labels so that the model can make accurate predictions on new, unseen data.\n",
    "\n",
    "Examples: Classification (assigning data points to predefined classes) and regression (predicting a continuous value) are common supervised learning tasks.\n",
    "\n",
    "Training: During training, the model adjusts its parameters to minimize the difference between its predictions and the actual labels in the training data.\n",
    "\n",
    "Evaluation: The model's performance is evaluated using metrics such as accuracy, precision, recall, and mean squared error.\n",
    "\n",
    "2.Unsupervised Learning:\n",
    "\n",
    "Definition: In unsupervised learning, the model is trained on an unlabeled dataset, meaning there are no corresponding output labels provided during training.\n",
    "\n",
    "Objective: The goal is to discover patterns, relationships, or structures within the data without any predefined target outputs.\n",
    "\n",
    "Examples: Clustering (grouping similar data points), dimensionality reduction (reducing the number of features while preserving information), and anomaly detection (finding outliers) are common unsupervised learning tasks.\n",
    "\n",
    "Training: The model learns to represent the inherent structure of the data, often by grouping similar data points together or finding underlying patterns.\n",
    "\n",
    "Evaluation: Evaluation in unsupervised learning can be more subjective and task-dependent, often involving visual inspection or other domain-specific methods.\n",
    "\n",
    "3.Semi-Supervised Learning:\n",
    "\n",
    "Definition: Semi-supervised learning is a combination of supervised and unsupervised learning. It uses a dataset that contains both labeled and unlabeled examples.\n",
    "\n",
    "Objective: The goal is to leverage the labeled examples to improve the learning process for both labeled and unlabeled data points.\n",
    "\n",
    "Use Cases: Semi-supervised learning is useful when obtaining labeled data is expensive or time-consuming, but unlabeled data is more readily available.\n",
    "\n",
    "Training: The model learns from both labeled data to predict labeled outputs and unlabeled data to capture the underlying structure of the data.\n",
    "\n",
    "Examples: Anomaly detection with limited labeled anomalies, where most data is unlabeled, or improving performance on a classification task with a small amount of labeled data.\n",
    "\n",
    "In summary:\n",
    "\n",
    "Supervised Learning: Uses labeled data to learn mappings from inputs to outputs for making predictions.\n",
    "\n",
    "Unsupervised Learning: Uses unlabeled data to discover patterns, relationships, or structures within the data.\n",
    "\n",
    "Semi-Supervised Learning: Utilizes a combination of labeled and unlabeled data to improve learning and generalization, especially when labeled data is limited."
   ]
  },
  {
   "cell_type": "raw",
   "id": "90ac78e0-dc0b-45d8-b5c5-9cea9fac6864",
   "metadata": {},
   "source": [
    "Q6- What is train, test and validation split? Explain the importance of each term.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a562a0-e2ea-497d-9dfe-bf11309cab48",
   "metadata": {},
   "source": [
    "In machine learning, the process of training and evaluating a model involves splitting the available dataset into three main subsets: training set, validation set, and test set. This split is crucial for developing models that generalize well to new, unseen data. Here's an explanation of each term and their importance:\n",
    "\n",
    "1.Training Set:\n",
    "\n",
    "The training set is a subset of the dataset used to train the model's parameters. It consists of input data and their corresponding output labels (in supervised learning).\n",
    "\n",
    "During training, the model learns patterns, relationships, and features in the data by adjusting its parameters to minimize the difference between its predictions and the actual labels.\n",
    "\n",
    "Importance: The training set is used to build the model's knowledge. It's where the model learns from examples and captures underlying patterns in the data.\n",
    "\n",
    "2.Validation Set:\n",
    "\n",
    "The validation set is a subset of the dataset that is not used during training but is used to fine-tune hyperparameters and assess the model's performance.\n",
    "\n",
    "It helps in monitoring the model's performance on unseen data and detecting issues like overfitting (when the model performs well on training data but poorly on new data) or underfitting (when the model is too simple to capture patterns).\n",
    "\n",
    "Importance: The validation set allows you to adjust model parameters and hyperparameters to achieve the best possible generalization performance without directly affecting the test set.\n",
    "\n",
    "3.Test Set:\n",
    "\n",
    "The test set is another subset of the dataset that is used to evaluate the final performance of the trained model. It's a proxy for unseen, real-world data.\n",
    "\n",
    "The test set should not be used during model development, parameter tuning, or any decisions that could bias the model's performance.\n",
    "\n",
    "Importance: The test set provides an unbiased assessment of the model's ability to generalize to new data. It gives an indication of how well the model will perform on new, unseen examples.\n",
    "\n",
    "Importance of Each Term:\n",
    "\n",
    "Training Set Importance: It's where the model learns from data and builds its understanding of patterns and relationships. A diverse and representative training set helps the model generalize well to various scenarios.\n",
    "\n",
    "Validation Set Importance: It's used to fine-tune hyperparameters, select the best model architecture, and monitor performance during training. This helps in avoiding overfitting and making informed decisions about the model's design.\n",
    "\n",
    "Test Set Importance: It provides an objective evaluation of the model's performance on unseen data. It's a critical step to assess how well the model will perform in real-world scenarios.\n",
    "\n",
    "It's important to maintain the separation between these sets. Mixing them can lead to biased assessments of model performance. Common split ratios are 70-15-15 or 80-10-10 for training-validation-test sets, depending on the size of your dataset and specific requirements. Cross-validation techniques are also used when datasets are limited to make better use of available data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f2eefe5-4692-4ecb-abed-05ec931f9146",
   "metadata": {},
   "source": [
    "Q7- How can unsupervised learning be used in anomaly detection?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c44ec5-0350-4d87-a20f-f595b2e9026f",
   "metadata": {},
   "source": [
    "Unsupervised learning is commonly used in anomaly detection to identify unusual or rare patterns in a dataset without requiring labeled examples of anomalies. Anomalies, also known as outliers, are data points that deviate significantly from the majority of the data and might indicate interesting or potentially problematic instances. Here's how unsupervised learning can be applied to anomaly detection:\n",
    "\n",
    "1.Clustering-Based Anomaly Detection:\n",
    "\n",
    "Clustering algorithms group similar data points together based on their features. Anomalies can be detected as data points that don't belong to any well-defined cluster or are far from all clusters.\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Detects anomalies as points that have low density or are far from dense regions.\n",
    "\n",
    "Isolation Forest: Builds an ensemble of decision trees that isolate anomalies in fewer splits.\n",
    "\n",
    "2.Density Estimation-Based Anomaly Detection:\n",
    "\n",
    "Density estimation models characterize the distribution of the data. Anomalies can be identified as data points with low probability density.\n",
    "\n",
    "Gaussian Mixture Models (GMM): Fits a mixture of Gaussian distributions to the data and considers data points with low probability as anomalies.\n",
    "\n",
    "Kernel Density Estimation: Estimates the probability density function and flags points with low density as anomalies.\n",
    "\n",
    "3.Autoencoder-Based Anomaly Detection:\n",
    "\n",
    "Autoencoders are neural networks that learn to encode and then decode data. Anomalies lead to higher reconstruction errors, allowing detection.\n",
    "\n",
    "Variational Autoencoders (VAEs): VAEs model the underlying distribution of the data and can identify data points with high reconstruction error as anomalies.\n",
    "\n",
    "Deep Autoencoders: Trained on normal data, these models produce higher reconstruction errors for anomalies.\n",
    "\n",
    "4.One-Class SVM (Support Vector Machine):\n",
    "\n",
    "One-Class SVM learns the boundary that encompasses the majority of data points and identifies anomalies as those outside the boundary.\n",
    "\n",
    "5.Local Outlier Factor (LOF):\n",
    "\n",
    "LOF calculates the local density deviation of a data point with respect to its neighbors. Anomalies have significantly lower density.\n",
    "\n",
    "6.Principal Component Analysis (PCA):\n",
    "\n",
    "PCA can be used to reduce the dimensionality of the data. Anomalies might be detected by considering data points with large reconstruction errors.\n",
    "\n",
    "7.Time Series Anomaly Detection:\n",
    "\n",
    "Unsupervised learning methods can be adapted to detect anomalies in time series data, such as network traffic or sensor readings.\n",
    "\n",
    "Seasonal Hybrid ESD (S-H-ESD): An extension of the ESD test for detecting anomalies in seasonal time series data.\n",
    "\n",
    "Isolation Forest for Time Series (iForestTS): Adapts isolation forest for anomaly detection in time series data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "26bf8e3b-5c52-48f4-9e5b-e30739a1772f",
   "metadata": {},
   "source": [
    "Q8- List down some commonly used supervised learning algorithms and unsupervised learning\n",
    "algorithms.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c665f85-b6ce-45db-9799-53126a63ab7b",
   "metadata": {},
   "source": [
    "Supervised Learning Algorithms:\n",
    "\n",
    "1.Linear Regression: Predicts a continuous output based on input features by fitting a linear equation.\n",
    "\n",
    "2.Logistic Regression: Used for binary classification, it estimates the probability of an input belonging to a certain class.\n",
    "\n",
    "3.Decision Trees: Hierarchical structure of rules used for classification and regression tasks.\n",
    "\n",
    "4.Random Forest: Ensemble of decision trees that improves performance and reduces overfitting.\n",
    "\n",
    "5.Support Vector Machines (SVM): Finds a hyperplane that best separates data points in different classes.\n",
    "\n",
    "6.K-Nearest Neighbors (KNN): Classifies data points based on the majority class among their k-nearest neighbors.\n",
    "\n",
    "7.Naive Bayes: Probabilistic algorithm based on Bayes' theorem for classification tasks.\n",
    "\n",
    "8.Gradient Boosting: Ensemble technique that combines weak learners to build a strong learner iteratively.\n",
    "\n",
    "9.Neural Networks: Complex models inspired by the human brain, suitable for various tasks, including image and text analysis.\n",
    "\n",
    "Unsupervised Learning Algorithms:\n",
    "\n",
    "1.K-Means Clustering: Divides data points into k clusters by minimizing the distance between points and the centroid of their assigned cluster.\n",
    "\n",
    "2.Hierarchical Clustering: Creates a hierarchical tree of clusters by iteratively merging or dividing clusters.\n",
    "\n",
    "3.DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Groups data points based on their density and isolates outliers.\n",
    "\n",
    "4.Gaussian Mixture Models (GMM): Represents data as a mixture of Gaussian distributions, used for density estimation and clustering.\n",
    "\n",
    "5.Principal Component Analysis (PCA): Reduces dimensionality by projecting data onto a lower-dimensional subspace that captures maximum variance.\n",
    "\n",
    "6.Autoencoders: Neural network architecture used for dimensionality reduction and feature extraction.\n",
    "\n",
    "7.t-SNE (t-Distributed Stochastic Neighbor Embedding): Reduces high-dimensional data while preserving local structure for visualization.\n",
    "\n",
    "8.Isolation Forest: Anomaly detection algorithm based on isolating anomalies in fewer splits compared to normal data.\n",
    "\n",
    "9.Local Outlier Factor (LOF): Measures the local density deviation of a data point relative to its neighbors, identifying anomalies.\n",
    "\n",
    "10.Mean Shift Clustering: Iteratively shifts data points towards the mode of the nearest data density function, used for clustering.\n",
    "\n",
    "Remember that the choice of algorithm depends on the nature of the problem, the characteristics of the data, and the specific goals you want to achieve. It's often a good idea to experiment with multiple algorithms and evaluate their performance to find the best fit for your task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
